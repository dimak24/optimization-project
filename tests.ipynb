{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import *\n",
    "from model import LogisticInstance\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1D case\n",
    "# e^{x-2} / (1 + e^{x-2}) (-x + 5) --> max\n",
    "# theoretical answer: x_opt ~ 2.44\n",
    "# with constraint x<=2 x_opt ~ 2\n",
    "\n",
    "a = np.array([1])\n",
    "b = -2\n",
    "c = np.array([-1])\n",
    "d = 5\n",
    "F = np.array([[1]])\n",
    "g = np.array([2])\n",
    "\n",
    "issue = LogisticInstance(a, b, c, d, F, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(method_name, method, real_f_name, real_f, **kwargs):\n",
    "    t = time.monotonic()\n",
    "    x_opt = method(**kwargs)\n",
    "    print('{}:\\n  x_opt = {}\\n  {} = {}\\n  time = {}s'.format(method_name, x_opt,\n",
    "                                                       real_f_name, real_f(x_opt),\n",
    "                                                       time.monotonic() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent, conv. by argument, h_k = 0.1:\n",
      "  x_opt = [2.44261703]\n",
      "  expected_profit = 1.5571455818420734\n",
      "  time = 0.013306218999787234s\n",
      "Gradient descent, conv. by argument, h_k = 1/k:\n",
      "  x_opt = [2.34713717]\n",
      "  expected_profit = 1.554373820931351\n",
      "  time = 0.1381585070012079s\n",
      "Gradient descent, conv. by argument, h_k = 1/sqrt(k):\n",
      "  x_opt = [2.44255797]\n",
      "  expected_profit = 1.5571455722441265\n",
      "  time = 0.00525409799956833s\n",
      "\n",
      "\n",
      "Accelerated Nesterov gradient descent, h_k = 0.5:\n",
      "  x_opt = [2.4427758]\n",
      "  expected_profit = 1.5571455971164652\n",
      "  time = 0.0014657469982921612s\n",
      "Accelerated Nesterov gradient descent, h_k = 1/sqrt(k):\n",
      "  x_opt = [2.44126018]\n",
      "  expected_profit = 1.5571448252478892\n",
      "  time = 0.0016612740000709891s\n"
     ]
    }
   ],
   "source": [
    "# unconditional optimization\n",
    "\n",
    "f = lambda x: -issue.log_expected_profit(x)\n",
    "df = lambda x: -issue.dlog_expected_profit(x)\n",
    "\n",
    "\n",
    "\n",
    "test('Gradient descent, conv. by argument, h_k = 0.1', \n",
    "     GradientDescent(h=0.1), \n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "test('Gradient descent, conv. by argument, h_k = 1/k', \n",
    "     GradientDescent(h=lambda step: 1. / step), \n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "test('Gradient descent, conv. by argument, h_k = 1/sqrt(k)', \n",
    "     GradientDescent(h=lambda step: step ** -0.5), \n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "test('Accelerated Nesterov gradient descent, h_k = 0.5', \n",
    "     AcceleratedNesterovGradientDescent(),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "test('Accelerated Nesterov gradient descent, h_k = 1/sqrt(k)', \n",
    "     AcceleratedNesterovGradientDescent(h=lambda step: step ** -0.5),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty method, pen_k = [1] * (k-1), ext_pen_func = max(0, x)^0.7,\n",
      "unconditional method -- gradient descent with h_k=0.01:\n",
      "  x_opt = [2.00233491]\n",
      "  expected_profit = 1.500582363040146\n",
      "  time = 0.0697340679980698s\n"
     ]
    }
   ],
   "source": [
    "# conditional\n",
    "\n",
    "# the previous issue (theoretically, x_opt=2)\n",
    "\n",
    "g = lambda x: np.dot(issue.F , x) -issue.g\n",
    "dg = lambda x: issue.F\n",
    "\n",
    "test('''Penalty method, pen_k = [1] * (k-1), ext_pen_func = max(0, x)^0.7,\n",
    "unconditional method -- gradient descent with h_k=0.01''', \n",
    "     PenaltyMethod(),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df,\n",
    "     g=g, dg=dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 2d issue\n",
    "# (x + y) / (1 + e^{x+y}) --> max\n",
    "# x + y <= 1\n",
    "#     y <= 0.5\n",
    "# theoretically, x_opt = (0.5, 0.5)\n",
    "\n",
    "a = np.array([-1, -1])\n",
    "b = 0\n",
    "c = np.array([1, 1])\n",
    "d = 0\n",
    "F = np.array([[1, 1],\n",
    "              [0, 1]])\n",
    "g = np.array([1, 0.5])\n",
    "\n",
    "issue = LogisticInstance(a, b, c, d, F, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty method, pen_k = [1] * (k-1), ext_pen_func = max(0, x)^0.7,\n",
      "unconditional method -- gradient descent with h_k=0.01:\n",
      "  x_opt = [0.50177973 0.50177973]\n",
      "  expected_profit = 0.26919696224432765\n",
      "  time = 0.03936207600054331s\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: -issue.log_expected_profit(x)\n",
    "df = lambda x: -issue.dlog_expected_profit(x)\n",
    "g = lambda x: np.dot(issue.F , x) -issue.g\n",
    "dg = lambda x: issue.F\n",
    "\n",
    "test('''Penalty method, pen_k = [1] * (k-1), ext_pen_func = max(0, x)^0.7,\n",
    "unconditional method -- gradient descent with h_k=0.01''', \n",
    "     PenaltyMethod(),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.ones(issue.a.shape[0]) * 0.01, df=df,\n",
    "     g=g, dg=dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
