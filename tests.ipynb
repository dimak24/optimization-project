{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import *\n",
    "from model import LogisticInstance\n",
    "import numpy as np\n",
    "from cvxopt import matrix, solvers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1D case\n",
    "# e^{x-2} / (1 + e^{x-2}) (-x + 5) --> max\n",
    "# theoretical answer: x_opt ~ 2.44\n",
    "# with constraint x<=2 x_opt ~ 2\n",
    "\n",
    "a = np.array([1.])\n",
    "b = -2.\n",
    "c = np.array([-1.])\n",
    "d = 5.\n",
    "F = np.array([[1.]])\n",
    "g = np.array([2.])\n",
    "\n",
    "issue = LogisticInstance(a, b, c, d, F, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(method_name, method, real_f_name, real_f, **kwargs):\n",
    "    t = time.monotonic()\n",
    "    x_opt = method(**kwargs)\n",
    "    print('{}:\\n  x_opt = {}\\n  {} = {}\\n  time = {}s'.format(method_name, x_opt,\n",
    "                                                       real_f_name, real_f(x_opt),\n",
    "                                                       time.monotonic() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent, conv. by argument, h_k = 0.1:\n",
      "  x_opt = [2.44261703]\n",
      "  expected_profit = 1.5571455818420734\n",
      "  time = 0.011479351000161842s\n",
      "Gradient descent, conv. by argument, h_k = 1/k:\n",
      "  x_opt = [2.34713717]\n",
      "  expected_profit = 1.554373820931351\n",
      "  time = 0.1339312929994776s\n",
      "Gradient descent, conv. by argument, h_k = 1/sqrt(k):\n",
      "  x_opt = [2.44255797]\n",
      "  expected_profit = 1.5571455722441265\n",
      "  time = 0.006747193001501728s\n",
      "\n",
      "\n",
      "Accelerated Nesterov gradient descent, h_k = 0.5:\n",
      "  x_opt = [2.4427758]\n",
      "  expected_profit = 1.5571455971164652\n",
      "  time = 0.0017869670009531546s\n",
      "Accelerated Nesterov gradient descent, h_k = 1/sqrt(k):\n",
      "  x_opt = [2.44126018]\n",
      "  expected_profit = 1.5571448252478892\n",
      "  time = 0.0018629240003065206s\n",
      "Broyden-Fletcher-Goldfarb-Shanno method (quasy-Newton):\n",
      "  x_opt = [2.4428544]\n",
      "  expected_profit = 1.557145598997611\n",
      "  time = 0.0005804309985251166s\n"
     ]
    }
   ],
   "source": [
    "# unconditional optimization\n",
    "\n",
    "f = lambda x: -issue.log_expected_profit(x)\n",
    "df = lambda x: -issue.dlog_expected_profit(x)\n",
    "d2f = lambda x: -issue.d2log_expected_profit(x)\n",
    "\n",
    "\n",
    "\n",
    "test('Gradient descent, conv. by argument, h_k = 0.1', \n",
    "     GradientDescent(h=0.1), \n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "test('Gradient descent, conv. by argument, h_k = 1/k', \n",
    "     GradientDescent(h=lambda step: 1. / step), \n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "test('Gradient descent, conv. by argument, h_k = 1/sqrt(k)', \n",
    "     GradientDescent(h=lambda step: step ** -0.5), \n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "test('Accelerated Nesterov gradient descent, h_k = 0.5', \n",
    "     AcceleratedNesterovGradientDescent(),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "test('Accelerated Nesterov gradient descent, h_k = 1/sqrt(k)', \n",
    "     AcceleratedNesterovGradientDescent(h=lambda step: step ** -0.5),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df)\n",
    "\n",
    "test('Broyden-Fletcher-Goldfarb-Shanno method (quasy-Newton)', \n",
    "     BroydenFletcherGoldfarbShannoMethod(),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.array([1.]), df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty method, pen_k = [1] * (k-1), ext_pen_func = max(0, x)^0.7,\n",
      "unconditional method -- gradient descent with h_k=0.01:\n",
      "  x_opt = [2.00233491]\n",
      "  expected_profit = 1.500582363040146\n",
      "  time = 0.09372364899900276s\n",
      "Optimal solution found.\n",
      "[ 2.00e+00]\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "# conditional\n",
    "\n",
    "# the previous issue (theoretically, x_opt=2)\n",
    "\n",
    "g = lambda x: np.dot(issue.F , x) -issue.g\n",
    "dg = lambda x: issue.F\n",
    "\n",
    "test('''Penalty method, pen_k = [1] * (k-1), ext_pen_func = max(0, x)^0.7,\n",
    "unconditional method -- gradient descent with h_k=0.01''', \n",
    "     PenaltyMethod(),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.zeros(issue.a.shape[0]), df=df,\n",
    "     g=g, dg=dg)\n",
    "\n",
    "# linear\n",
    "A = matrix(-issue.a)\n",
    "B = matrix([issue.b])\n",
    "F = matrix(issue.F)\n",
    "G = matrix(issue.g)\n",
    "\n",
    "\n",
    "sol = solvers.lp(A, F, G)\n",
    "print(sol['x'], issue.prob(np.array(sol['x'])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 2d issue\n",
    "# (x + y) / (1 + e^{x+y}) --> max\n",
    "# x + y <= 1\n",
    "#     y <= 0.5\n",
    "# theoretically, x_opt = (0.5, 0.5)\n",
    "\n",
    "a = np.array([-1., -1.])\n",
    "b = 0\n",
    "c = np.array([1., 1.])\n",
    "d = 0\n",
    "F = np.array([[1., 1.],\n",
    "              [0., 1.]])\n",
    "g = np.array([1., 0.5])\n",
    "\n",
    "issue = LogisticInstance(a, b, c, d, F, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty method, pen_k = [1] * (k-1), ext_pen_func = max(0, x)^0.7,\n",
      "unconditional method -- gradient descent with h_k=0.01:\n",
      "  x_opt = [0.50177973 0.50177973]\n",
      "  expected_profit = 0.26919696224432765\n",
      "  time = 0.04589946100168163s\n",
      "     pcost       dcost       gap    pres   dres   k/t\n",
      " 0:  1.0000e+00 -2.0000e+00  3e+00  1e+00  3e+00  1e+00\n",
      " 1: -9.8000e+01 -2.0000e+00  3e+02  1e+00  3e+00  1e+02\n",
      " 2: -9.9980e+03 -2.0000e+00  3e+04  1e+00  3e+00  1e+04\n",
      " 3: -1.0000e+06 -2.0000e+00  3e+06  1e+00  3e+00  1e+06\n",
      " 4: -1.0000e+08 -2.0000e+00  3e+08  1e+00  3e+00  1e+08\n",
      "Certificate of dual infeasibility found.\n",
      "[ 5.00e-09]\n",
      "[-1.00e+00]\n",
      " 0.7310585786300049\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: -issue.log_expected_profit(x)\n",
    "df = lambda x: -issue.dlog_expected_profit(x)\n",
    "g = lambda x: np.dot(issue.F , x) -issue.g\n",
    "dg = lambda x: issue.F\n",
    "\n",
    "test('''Penalty method, pen_k = [1] * (k-1), ext_pen_func = max(0, x)^0.7,\n",
    "unconditional method -- gradient descent with h_k=0.01''', \n",
    "     PenaltyMethod(),\n",
    "     'expected_profit', issue.expected_profit,\n",
    "     f=f, x0=np.ones(issue.a.shape[0]) * 0.01, df=df,\n",
    "     g=g, dg=dg)\n",
    "\n",
    "# linear\n",
    "A = matrix(-issue.a)\n",
    "B = matrix([issue.b])\n",
    "F = matrix(issue.F)\n",
    "G = matrix(issue.g)\n",
    "\n",
    "\n",
    "sol = solvers.lp(A, F, G)\n",
    "print('  x_opt = 'sol['x'], issue.prob(np.array(sol['x']).T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres   k/t\n",
      " 0:  1.0000e+00 -2.0000e+00  3e+00  1e+00  3e+00  1e+00\n",
      " 1: -9.8000e+01 -2.0000e+00  3e+02  1e+00  3e+00  1e+02\n",
      " 2: -9.9980e+03 -2.0000e+00  3e+04  1e+00  3e+00  1e+04\n",
      " 3: -1.0000e+06 -2.0000e+00  3e+06  1e+00  3e+00  1e+06\n",
      " 4: -1.0000e+08 -2.0000e+00  3e+08  1e+00  3e+00  1e+08\n",
      "Certificate of dual infeasibility found.\n",
      "[ 5.00e-09]\n",
      "[-1.00e+00]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = matrix(-issue.a)\n",
    "B = matrix([issue.b])\n",
    "F = matrix(issue.F)\n",
    "G = matrix(issue.g)\n",
    "\n",
    "\n",
    "sol = solvers.lp(A, F, G)\n",
    "print(sol['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
